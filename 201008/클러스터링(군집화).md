# 클러스터링(군집화)

분류와 다른 개념.(지도학습) : 데이터, 라벨 모두 존재 -> 데이터의 카테고리(라벨) 관계 파악 -> 새롭게 입력된 데이터의 카테고리를 판별하는 과정(새로 입력 된 데이터가 어느 라벨에 속할 것인지)

(비지도학습) : 데이터만 존재 -> 데이터간의 유사도를 정의 -> 유사도가 가까운 것부터 순서대로 합해가는 알고리즘(유사한 특성을 지닌 데이터들을 군집화하여 라벨링을 함)

데이터 전처리가 중요.

클러스터의 개수를 선택하는 것 중요

알고리즘 : 동일 클러스터 내의 데이터들의 거리는 가깝게, 클러스터간의 거리는 멀게

거리 측정 방법 : 유클리드 거리, 맨하탄 거리 등등

종류 : 

- k-means : k개의 클러스터로 나누어 클러스터 내 거리제곱의 합을 최소화하는 방법
  1. k개 random값 발생 -> k개 클러스터의 초기 중심점(k centroid points) 설정
  2. 각 클러스터의 중심점들과 모든 데이터 사이의 거리를 구하기
  3. 각 데이터를 가장 가까운 거리에 있는 클러스터의 중심점에 할당
  4. 각 클러스터 내의 데이터들의 중심점을 계산 -> k개의 각 클러스터 중심점을 업데이트
  5. 더이상 클러스터의 중심점이 변화하지 않을 때까지 2~4번의 과정을 반복한다.
  
  한계 : 아래의 상황의 경우 군집화를 올바르게 하지 못한다.
  
  - 각 클러스터의 밀도가 다를때
  - 태극기 모양으로 데이터가 분포되어있을때
  
  극복법:
  
  - majority voting : k-means를 여러번 시행하여 가장 빈번하게 등장하는 군집에 할당

- H-clustering : 

  - 계층적 트리 모델, 클러스터 수를 주지 않아도 됌. 

  - 덴드로그램(Dendrogram) : 데이터들이 묶이는 순서를 나타낸 트리구조(토너먼트 형태)의 형태로 트리를 형성 => 클러스터의 수를 결정

  - 데이터 간 트리를 구성해 원하는 클러스터 수 만큼의 트리에서 가지치기

  - 데이터들간의 거리 또는 유사도가 미리 계산 되어 있어야 함 

    => __거리행렬__을 이용하여 가장 가까운 거리에 있는 것 끼리 군집화 → 갱신을 반복

    => 클러스터와 데이터 간의 거리를 갱신하는 방법 : 

     	1. min distance : 각 클러스터에서 서로 가장 가까운 데이터 간의 거리
     	2. max distance : 각 클러스터에서 서로 가장 멀리 떨어진 데이터 간의 거리
     	3. centroid point : 클러스터 중심점과의 거리
     	4. fully-connected : 클러스터 간 모든 데이터의 거리를 구해 평균 

- DBSCAN

  - `eps(epsilon)` : 특정한 1개의 데이터 P(core point)로부터 일정 거리 안의 데이터가 minPts개 이상(본인 포함) 있으면 클러스터로 인식
  - P2라는 또다른 데이터를 기준으로 클러스터를 구성할 때, 내부의 데이터 갯수가 minPts는 만족하지 못하지만 P(core point)데이터가 존재하면 P2를 **border point(경계점)**이라고 부른다.
  - P3라는 데이터를 기준으로 클러스터를 구성할 때, 내부의 데이터 갯수가 minPts를 만족하고 P(core point)데이터가 존재하면 P3는 P와 연결된 **1개의 클러스터**로 취급한다.
  - `outlier` : 어느 군집에도 포함되지 않는 데이터





R코드(`kmeans(data, k)`)

` cluster`

`centers` : 클러스터의 중심점

> ex)  iris는 4차원(features 개수가 4개) 데이터 => 3개 클러스터로 분류해보자
>  =>3개 클러스터에 대한 중심점의 좌표 확인(centers)이 필요하다.
> 
> > 1 cluster의 cp : (5.7, 2.5, 1.3, 0.15)
> > 2 cluster의 cp : (4.7, 1.5, 1.3, 0.15)
> > 3 cluster의 cp : (3.7, 2.7, 1.3, 0.15)
> > (3행 4열)

`tot.withiness`



`kmeans()$centers` : 각 클러스터의 중심점 출력

`kmeans()$cluster` : 각 데이터가 어떤 클러스터에 할당되었는지를 확인하는 코드

`kmeans()$withisnss` : 클러스터 내에서 중심점으로부터 데이터와의 거리(응집력)



# 군집분석

군집화 후 분석하는 과정



# 기계학습 알고리즘

- 지도학습 : 문제와 답이 있는 학습. 오버피팅의 위험이 있음. ex) RF, DT
- 비지도학습
- 강화학습