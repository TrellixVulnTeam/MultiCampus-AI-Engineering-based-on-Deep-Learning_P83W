# 랜덤포레스트



* 나무생성 알고리즘 : 배깅

  * 트리는 홀수개로 생성하는 것이 좋음. 

  * 데이터 복원추출 

  * 트리작성시 사용될 feature들을 제한(전체 속성 개수의 제곱근이 가장 좋음) -> 나무에 대한 다양성

* 중요 옵션 :

  최적의 랜덤포레스트 파라미터를 찾는게 중요!  [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearch) 를 사용해서 랜덤포레스트 하이퍼 파라미터 튜닝 가능

  * `n_estimators` : 생성할 트리의 개수(기본: 100), 크게 할 수록 좋음(시간은 오래걸림)
  * `max_depth` : 트리의 최대 깊이(기본: None -> 완전하게 클래스 값이 결정될 되도록 트리의 가장 끝까지 분할한다 -> 과적합 문제). 과적합(훈련데이터에 최적화 된 모델) 방지를 위한 옵션
  * `min_samples_split` : 노드를 분할하기 위한 최소한의 데이터수(과적합 방지). 작게 설정할 수록 분할 노드가 많아지므로 과적합이 증가할 수 있음.
  * `min_samples_leaf` : 리프노드(터미널노드)가 되기 위해 필요로 하는 최소한의 샘플 데이터 수. 일반적으로 작게 설정

  

​	*ex) 학습데이터 1000개 -> 임의로 100개 데이터 선택(31번 반복) => 트리(31개)구성* 



---

참고 사이트 : [ sklearn.ensemble.RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)