# 신경망 

- 활용 : 자동차 번호판 인식, 손글씨 인식(우편번호 분류기)

- 신경망의 반복 학습으로 최적의 분류, 예측 모델을 만듦.

- 학습과정 (선형관계라고 가정)
  - 분류일 때

    1. 임의의 분할 선을 만든다	*ex) y = Ax+B*

    2. 학습데이터를 이용하여 분류한 `예측값`과 실제 값을 비교하여 오차를 구한다.

    3. 학습데이터의 독립변수를 훈련시켰을 때 종속변수가 실제 값을 포함하도록 `목표값`을 설정하여 직선의 기울기(A)와 절편(B)을 바꾸어 훈련한다.

    4. 오차(E) = `목표값` - `예측값` = 기울기의 변화값(*△Ax*)

       => 오차는 기울기를 변경하여 줄일 수 있다.

    5. 기존의 기울기에 *△A*를 더하여 새로운 모델로 업데이트 한다.

    6. 2-5까지의 과정을 모든 데이터에 대해 f여러번 반복한다.

  

  문제 : 마지막 학습한 데이터에 최적화 된 모델이 생성되어 과적합의 위험이 있다.

  => *△A*의 일부씩만 업데이트 할 필요가 있다.(`가중치`)

  => Learning Rate 등장 (*△A* * learning rate 만 적용하여 업데이트)



- 활성화 함수 : 임계점을 넘느냐 안넘느냐를 판단하여 출력을 생성할지 말지를 결정하는 함수?

​	*ex) 시그모이드, 계단, 하이퍼볼릭탄젠트(쌍곡, tanh), Relu, softmax 등*

>- 시그모이드 함수
>
> - 수식 : 1/1+e^-z
>
>   > z가 0 이면 sig함수 : 0.5
>   >
>   > z가 -∞이면 sig함수 : 0
>   >
>   > z가 ∞이면 sig함수 : 1
>   
>   z = wx+b
>
> 0~1 사이의 값을 갖는다. => __sig함수가 0.5이상인 경우만 신호를 전달한다.__



- 여러개의 데이터를 입력 받은 후 시그모이드 함수로 신호를 전달받은 값들의 합을 구하는 것이 일반적인 신경망의 구조.

- 여러 계층의 뉴런(노드)로 구성되어 있고 각 계층 별로 상호 연결 관계를 갖는다. -> 연결 강도를 조정하는 것을 `가중치`라고 함.

- 행렬의 곱셈 : 신경망 구조의 가중치 및 활성화 함수 계산을 쉽게 하기 위한 수단

  >1. 신호*가중치 행렬 = 결과 신호
  >2. sigmoid(결과)
  >3. 2이 결과는 0과 1사이의 값을 갖는다.



# XOR문제

하나의 직선모델로는 어떤 모델이라도 데이터를 분류 및 예측 하지 못하는 경우를 일컫는 말

=> 여러개의 분류 모델을 사용해야함