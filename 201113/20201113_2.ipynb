{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "gray_scale = 255\n",
    "x_train /= gray_scale\n",
    "x_test /= gray_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)), # 데이터 차원 변경\n",
    "    Dense(256, activation='relu'), # 첫번째 히든 레이어 (h1)\n",
    "    Dense(128, activation='relu'), # 두번째 히든 레이어 (h2)\n",
    "    Dropout(0.1), # 두번째 히든 레이어(h2)에 드랍아웃(10%) 적용\n",
    "    Dense(10), # 세번째 히든 레이어 (logit, score)\n",
    "    Activation('softmax') # softmax layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_accuracy', patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 2.2809 - accuracy: 0.2545 - val_loss: 2.2492 - val_accuracy: 0.3342\n",
      "Epoch 2/300\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 2.2013 - accuracy: 0.3999 - val_loss: 2.1329 - val_accuracy: 0.5292\n",
      "Epoch 3/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 2.0571 - accuracy: 0.5478 - val_loss: 1.9523 - val_accuracy: 0.6460\n",
      "Epoch 4/300\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 1.8637 - accuracy: 0.6386 - val_loss: 1.7371 - val_accuracy: 0.6837\n",
      "Epoch 5/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 1.6551 - accuracy: 0.6896 - val_loss: 1.5252 - val_accuracy: 0.7643\n",
      "Epoch 6/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 1.4606 - accuracy: 0.7304 - val_loss: 1.3366 - val_accuracy: 0.7787\n",
      "Epoch 7/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 1.2934 - accuracy: 0.7556 - val_loss: 1.1775 - val_accuracy: 0.7980\n",
      "Epoch 8/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 1.1547 - accuracy: 0.7743 - val_loss: 1.0469 - val_accuracy: 0.8155\n",
      "Epoch 9/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 1.0410 - accuracy: 0.7912 - val_loss: 0.9405 - val_accuracy: 0.8297\n",
      "Epoch 10/300\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.9473 - accuracy: 0.8039 - val_loss: 0.8516 - val_accuracy: 0.8450\n",
      "Epoch 11/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.8692 - accuracy: 0.8150 - val_loss: 0.7774 - val_accuracy: 0.8560\n",
      "Epoch 12/300\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.8034 - accuracy: 0.8255 - val_loss: 0.7149 - val_accuracy: 0.8603\n",
      "Epoch 13/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.7478 - accuracy: 0.8329 - val_loss: 0.6621 - val_accuracy: 0.8682\n",
      "Epoch 14/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.7002 - accuracy: 0.8410 - val_loss: 0.6167 - val_accuracy: 0.8772\n",
      "Epoch 15/300\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.6593 - accuracy: 0.8473 - val_loss: 0.5773 - val_accuracy: 0.8793\n",
      "Epoch 16/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.6239 - accuracy: 0.8531 - val_loss: 0.5434 - val_accuracy: 0.8830\n",
      "Epoch 17/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.5930 - accuracy: 0.8587 - val_loss: 0.5137 - val_accuracy: 0.8890\n",
      "Epoch 18/300\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.5660 - accuracy: 0.8628 - val_loss: 0.4883 - val_accuracy: 0.8927\n",
      "Epoch 19/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.5420 - accuracy: 0.8681 - val_loss: 0.4651 - val_accuracy: 0.8973\n",
      "Epoch 20/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.5208 - accuracy: 0.8725 - val_loss: 0.4454 - val_accuracy: 0.8998\n",
      "Epoch 21/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.5019 - accuracy: 0.8757 - val_loss: 0.4279 - val_accuracy: 0.9017\n",
      "Epoch 22/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.4851 - accuracy: 0.8788 - val_loss: 0.4120 - val_accuracy: 0.9047\n",
      "Epoch 23/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.4699 - accuracy: 0.8811 - val_loss: 0.3978 - val_accuracy: 0.9070\n",
      "Epoch 24/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.4563 - accuracy: 0.8831 - val_loss: 0.3851 - val_accuracy: 0.9083\n",
      "Epoch 25/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.4439 - accuracy: 0.8855 - val_loss: 0.3739 - val_accuracy: 0.9102\n",
      "Epoch 26/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.4331 - accuracy: 0.8878 - val_loss: 0.3641 - val_accuracy: 0.9108\n",
      "Epoch 27/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.4227 - accuracy: 0.8893 - val_loss: 0.3543 - val_accuracy: 0.9123\n",
      "Epoch 28/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.4135 - accuracy: 0.8911 - val_loss: 0.3458 - val_accuracy: 0.9123\n",
      "Epoch 29/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.4049 - accuracy: 0.8923 - val_loss: 0.3380 - val_accuracy: 0.9133\n",
      "Epoch 30/300\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.3972 - accuracy: 0.8934 - val_loss: 0.3313 - val_accuracy: 0.9157\n",
      "Epoch 31/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.3900 - accuracy: 0.8949 - val_loss: 0.3247 - val_accuracy: 0.9160\n",
      "Epoch 32/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.3834 - accuracy: 0.8961 - val_loss: 0.3191 - val_accuracy: 0.9173\n",
      "Epoch 33/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.3773 - accuracy: 0.8970 - val_loss: 0.3132 - val_accuracy: 0.9172\n",
      "Epoch 34/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.3715 - accuracy: 0.8987 - val_loss: 0.3090 - val_accuracy: 0.9180\n",
      "Epoch 35/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.3662 - accuracy: 0.8997 - val_loss: 0.3037 - val_accuracy: 0.9197\n",
      "Epoch 36/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.3614 - accuracy: 0.9007 - val_loss: 0.2992 - val_accuracy: 0.9195\n",
      "Epoch 37/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.3565 - accuracy: 0.9011 - val_loss: 0.2955 - val_accuracy: 0.9205\n",
      "Epoch 38/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.3523 - accuracy: 0.9025 - val_loss: 0.2910 - val_accuracy: 0.9208\n",
      "Epoch 39/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.3483 - accuracy: 0.9031 - val_loss: 0.2879 - val_accuracy: 0.9218\n",
      "Epoch 40/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.3443 - accuracy: 0.9039 - val_loss: 0.2847 - val_accuracy: 0.9218\n",
      "Epoch 41/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.3405 - accuracy: 0.9052 - val_loss: 0.2815 - val_accuracy: 0.9227\n",
      "Epoch 42/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.3372 - accuracy: 0.9056 - val_loss: 0.2780 - val_accuracy: 0.9238\n",
      "Epoch 43/300\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.3338 - accuracy: 0.9061 - val_loss: 0.2757 - val_accuracy: 0.9240\n",
      "Epoch 44/300\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.3308 - accuracy: 0.9069 - val_loss: 0.2727 - val_accuracy: 0.9255\n",
      "Epoch 45/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.3278 - accuracy: 0.9079 - val_loss: 0.2702 - val_accuracy: 0.9248\n",
      "Epoch 46/300\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.3249 - accuracy: 0.9084 - val_loss: 0.2679 - val_accuracy: 0.9260\n",
      "Epoch 47/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.3222 - accuracy: 0.9089 - val_loss: 0.2651 - val_accuracy: 0.9275\n",
      "Epoch 48/300\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3194 - accuracy: 0.9096 - val_loss: 0.2634 - val_accuracy: 0.9270\n",
      "Epoch 49/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.3172 - accuracy: 0.9105 - val_loss: 0.2611 - val_accuracy: 0.9273\n",
      "Epoch 50/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.3147 - accuracy: 0.9109 - val_loss: 0.2590 - val_accuracy: 0.9287\n",
      "Epoch 51/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.3125 - accuracy: 0.9113 - val_loss: 0.2578 - val_accuracy: 0.9292\n",
      "Epoch 52/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.3102 - accuracy: 0.9122 - val_loss: 0.2552 - val_accuracy: 0.9287\n",
      "Epoch 53/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.3081 - accuracy: 0.9123 - val_loss: 0.2536 - val_accuracy: 0.9303\n",
      "Epoch 54/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.3061 - accuracy: 0.9127 - val_loss: 0.2520 - val_accuracy: 0.9283\n",
      "Epoch 55/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.3040 - accuracy: 0.9136 - val_loss: 0.2505 - val_accuracy: 0.9302\n",
      "Epoch 56/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.3023 - accuracy: 0.9139 - val_loss: 0.2492 - val_accuracy: 0.9285\n",
      "Epoch 57/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.3003 - accuracy: 0.9142 - val_loss: 0.2466 - val_accuracy: 0.9312\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 10ms/step - loss: 0.2982 - accuracy: 0.9148 - val_loss: 0.2455 - val_accuracy: 0.9305\n",
      "Epoch 59/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.2965 - accuracy: 0.9154 - val_loss: 0.2442 - val_accuracy: 0.9288\n",
      "Epoch 60/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.2949 - accuracy: 0.9161 - val_loss: 0.2427 - val_accuracy: 0.9315\n",
      "Epoch 61/300\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2934 - accuracy: 0.9158 - val_loss: 0.2412 - val_accuracy: 0.9317\n",
      "Epoch 62/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.2914 - accuracy: 0.9166 - val_loss: 0.2401 - val_accuracy: 0.9315\n",
      "Epoch 63/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.2898 - accuracy: 0.9170 - val_loss: 0.2383 - val_accuracy: 0.9320\n",
      "Epoch 64/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.2882 - accuracy: 0.9175 - val_loss: 0.2370 - val_accuracy: 0.9325\n",
      "Epoch 65/300\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.2867 - accuracy: 0.9173 - val_loss: 0.2359 - val_accuracy: 0.9322\n",
      "Epoch 66/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.2852 - accuracy: 0.9179 - val_loss: 0.2353 - val_accuracy: 0.9318\n",
      "Epoch 67/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.2837 - accuracy: 0.9189 - val_loss: 0.2337 - val_accuracy: 0.9330\n",
      "Epoch 68/300\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2823 - accuracy: 0.9192 - val_loss: 0.2327 - val_accuracy: 0.9325\n",
      "Epoch 69/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.2810 - accuracy: 0.9193 - val_loss: 0.2315 - val_accuracy: 0.9328\n",
      "Epoch 70/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.2794 - accuracy: 0.9198 - val_loss: 0.2299 - val_accuracy: 0.9350\n",
      "Epoch 71/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.2778 - accuracy: 0.9204 - val_loss: 0.2294 - val_accuracy: 0.9338\n",
      "Epoch 72/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.2765 - accuracy: 0.9213 - val_loss: 0.2279 - val_accuracy: 0.9343\n",
      "Epoch 73/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.2751 - accuracy: 0.9209 - val_loss: 0.2270 - val_accuracy: 0.9342\n",
      "Epoch 74/300\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.2736 - accuracy: 0.9211 - val_loss: 0.2258 - val_accuracy: 0.9350\n",
      "Epoch 75/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.2723 - accuracy: 0.9219 - val_loss: 0.2250 - val_accuracy: 0.9345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2378ce8c640>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=300, batch_size=1000, validation_split = 0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss, test acc: [0.1666928231716156, 0.9514999985694885]\n"
     ]
    }
   ],
   "source": [
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_train = np.reshape(x_train, (60000,28,28,1))\n",
    "x_test = np.reshape(x_test, (10000,28,28,1))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "gray_scale = 255\n",
    "x_train /= gray_scale\n",
    "x_test /= gray_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1),padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               200832    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 215,370\n",
      "Trainable params: 215,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_accuracy', patience=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "108/108 [==============================] - 26s 245ms/step - loss: 0.4694 - accuracy: 0.8717 - val_loss: 0.1088 - val_accuracy: 0.9690\n",
      "Epoch 2/5\n",
      "108/108 [==============================] - 26s 241ms/step - loss: 0.1045 - accuracy: 0.9691 - val_loss: 0.0737 - val_accuracy: 0.9798\n",
      "Epoch 3/5\n",
      "108/108 [==============================] - 25s 227ms/step - loss: 0.0712 - accuracy: 0.9784 - val_loss: 0.0555 - val_accuracy: 0.9855\n",
      "Epoch 4/5\n",
      "108/108 [==============================] - 24s 221ms/step - loss: 0.0541 - accuracy: 0.9831 - val_loss: 0.0521 - val_accuracy: 0.9852\n",
      "Epoch 5/5\n",
      "108/108 [==============================] - 24s 223ms/step - loss: 0.0446 - accuracy: 0.9865 - val_loss: 0.0444 - val_accuracy: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2378d1fa550>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=500,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_split = 0.1, \n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.04033934324979782\n",
      "Test accuracy: 0.9876000285148621\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
