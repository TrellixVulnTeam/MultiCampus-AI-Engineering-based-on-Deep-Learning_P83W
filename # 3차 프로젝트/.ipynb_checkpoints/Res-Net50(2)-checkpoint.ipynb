{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31280 images belonging to 391 classes.\n",
      "Found 3910 images belonging to 391 classes.\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 230, 230, 3)  0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 112, 112, 64) 9472        zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 112, 112, 64) 256         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 112, 112, 64) 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 114, 114, 64) 0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 64)   0           zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 56, 56, 64)   4160        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 56, 56, 64)   256         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 56, 56, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 56, 56, 64)   36928       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 56, 56, 64)   256         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 56, 56, 64)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 56, 56, 256)  16640       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 56, 56, 256)  16640       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 56, 56, 256)  1024        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 56, 56, 256)  1024        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 56, 56, 256)  0           batch_normalization_57[0][0]     \n",
      "                                                                 batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 56, 56, 256)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 56, 56, 64)   16448       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 56, 56, 64)   256         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 56, 56, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 56, 56, 64)   36928       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 56, 56, 64)   256         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 56, 56, 64)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 56, 56, 256)  16640       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 56, 56, 256)  1024        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 56, 56, 256)  0           batch_normalization_61[0][0]     \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 56, 56, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 56, 56, 64)   16448       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 56, 56, 64)   256         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 56, 56, 64)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 56, 56, 64)   36928       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 56, 56, 64)   256         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 56, 56, 64)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 56, 56, 256)  16640       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 56, 56, 256)  1024        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 56, 56, 256)  0           batch_normalization_64[0][0]     \n",
      "                                                                 activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 56, 56, 256)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 28, 28, 128)  32896       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 28, 28, 128)  512         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 28, 28, 128)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 28, 28, 128)  147584      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 28, 28, 128)  512         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 28, 28, 128)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 28, 28, 512)  66048       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 28, 28, 512)  131584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 28, 28, 512)  2048        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 28, 28, 512)  2048        conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 512)  0           batch_normalization_67[0][0]     \n",
      "                                                                 batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 28, 28, 512)  0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 28, 28, 128)  65664       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 28, 28, 128)  512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 28, 28, 128)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 28, 28, 128)  147584      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 28, 28, 128)  512         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 28, 28, 128)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 28, 28, 512)  66048       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 28, 28, 512)  2048        conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 28, 28, 512)  0           batch_normalization_71[0][0]     \n",
      "                                                                 activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 28, 28, 512)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 28, 28, 128)  65664       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 28, 28, 128)  512         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 28, 28, 128)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 28, 28, 128)  147584      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 28, 28, 128)  512         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 28, 28, 128)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 28, 28, 512)  66048       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 28, 28, 512)  2048        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 28, 28, 512)  0           batch_normalization_74[0][0]     \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 28, 28, 512)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 28, 28, 128)  65664       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 28, 28, 128)  512         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 28, 28, 128)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 28, 28, 128)  147584      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 28, 28, 128)  512         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 28, 28, 128)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 28, 28, 512)  66048       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 28, 28, 512)  2048        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 28, 28, 512)  0           batch_normalization_77[0][0]     \n",
      "                                                                 activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 28, 28, 512)  0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 14, 14, 256)  131328      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 14, 14, 256)  1024        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 14, 14, 256)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 14, 14, 256)  590080      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 14, 14, 256)  1024        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 14, 14, 256)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 14, 14, 1024) 263168      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 14, 14, 1024) 525312      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 14, 14, 1024) 4096        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 14, 14, 1024) 4096        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_80[0][0]     \n",
      "                                                                 batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 14, 14, 1024) 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 14, 14, 256)  262400      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 14, 14, 256)  1024        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 14, 14, 256)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 14, 14, 256)  590080      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 14, 14, 256)  1024        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 14, 14, 256)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 14, 14, 1024) 263168      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 14, 14, 1024) 4096        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_84[0][0]     \n",
      "                                                                 activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 14, 14, 1024) 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 14, 14, 256)  262400      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 14, 14, 256)  1024        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 14, 14, 256)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 14, 14, 256)  590080      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 14, 14, 256)  1024        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 14, 14, 256)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 14, 14, 1024) 263168      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 14, 14, 1024) 4096        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_87[0][0]     \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 14, 14, 1024) 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 14, 14, 256)  262400      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 14, 14, 256)  1024        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 14, 14, 256)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 14, 14, 256)  590080      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 14, 14, 256)  1024        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 14, 14, 256)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 14, 14, 1024) 263168      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 14, 14, 1024) 4096        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_90[0][0]     \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 14, 14, 1024) 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 14, 14, 256)  262400      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 14, 14, 256)  1024        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 14, 14, 256)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 14, 14, 256)  590080      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 14, 14, 256)  1024        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 14, 14, 256)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 14, 14, 1024) 263168      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 14, 14, 1024) 4096        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_93[0][0]     \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 14, 14, 1024) 0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 14, 14, 256)  262400      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 14, 14, 256)  1024        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 14, 14, 256)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 14, 14, 256)  590080      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 14, 14, 256)  1024        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 14, 14, 256)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 14, 14, 1024) 263168      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 14, 14, 1024) 4096        conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_96[0][0]     \n",
      "                                                                 activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 14, 14, 1024) 0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 7, 7, 512)    524800      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 7, 7, 512)    2048        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 7, 7, 512)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 7, 7, 512)    2359808     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 7, 7, 512)    2048        conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 7, 7, 512)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 7, 7, 2048)   2099200     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 7, 7, 2048)   8192        conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 7, 7, 2048)   8192        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_99[0][0]     \n",
      "                                                                 batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 7, 7, 2048)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 7, 7, 512)    1049088     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 7, 7, 512)    2048        conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 7, 7, 512)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 7, 7, 512)    2359808     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 7, 7, 512)    2048        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 7, 7, 512)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 7, 7, 2048)   8192        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_103[0][0]    \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 7, 7, 2048)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 7, 7, 512)    1049088     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 7, 7, 512)    2048        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 7, 7, 512)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 7, 7, 512)    2359808     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 7, 7, 512)    2048        conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 7, 7, 512)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 7, 7, 2048)   8192        conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_106[0][0]    \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 7, 7, 2048)   0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 2048)         0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 391)          801159      global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 24,388,871\n",
      "Trainable params: 24,335,751\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "from keras import Input\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
    " \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_dir = os.path.join('C:/Users/USER/Desktop/여기요/서울시_ttv/train')\n",
    "val_dir = os.path.join('C:/Users/USER/Desktop/여기요/서울시_ttv/val')\n",
    " \n",
    " \n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(train_dir, batch_size=16, target_size=(224, 224), color_mode='rgb')\n",
    "val_generator = val_datagen.flow_from_directory(val_dir, batch_size=16, target_size=(224, 224), color_mode='rgb')\n",
    "\n",
    "# number of classes\n",
    "K = 391 #나중에 캠퍼스 추가\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(224, 224, 3), dtype='float32', name='input')\n",
    " \n",
    "    \n",
    "def conv1_layer(x):    \n",
    "    x = ZeroPadding2D(padding=(3, 3))(x)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ZeroPadding2D(padding=(1,1))(x)\n",
    " \n",
    "    return x   \n",
    " \n",
    "    \n",
    "\n",
    "def conv2_layer(x):         \n",
    "    x = MaxPooling2D((3, 3), 2)(x)     \n",
    " \n",
    "    shortcut = x\n",
    " \n",
    "    for i in range(3):\n",
    "        if (i == 0):\n",
    "            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(shortcut)            \n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    " \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    " \n",
    "        else:\n",
    "            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])   \n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            shortcut = x        \n",
    "    \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "def conv3_layer(x):        \n",
    "    shortcut = x    \n",
    "    \n",
    "    for i in range(4):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(128, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)            \n",
    " \n",
    "            x = Add()([x, shortcut])    \n",
    "            x = Activation('relu')(x)    \n",
    " \n",
    "            shortcut = x              \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(128, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])     \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            shortcut = x      \n",
    "            \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "def conv4_layer(x):\n",
    "    shortcut = x        \n",
    "  \n",
    "    for i in range(6):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(256, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(1024, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    " \n",
    "            x = Add()([x, shortcut]) \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            shortcut = x               \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])    \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            shortcut = x      \n",
    " \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "def conv5_layer(x):\n",
    "    shortcut = x    \n",
    "  \n",
    "    for i in range(3):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(2048, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)            \n",
    " \n",
    "            x = Add()([x, shortcut])  \n",
    "            x = Activation('relu')(x)      \n",
    " \n",
    "            shortcut = x               \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)           \n",
    "            \n",
    "            x = Add()([x, shortcut]) \n",
    "            x = Activation('relu')(x)       \n",
    " \n",
    "            shortcut = x                  \n",
    " \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "x = conv1_layer(input_tensor)\n",
    "x = conv2_layer(x)\n",
    "x = conv3_layer(x)\n",
    "x = conv4_layer(x)\n",
    "x = conv5_layer(x)\n",
    " \n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output_tensor = Dense(K, activation='softmax')(x)\n",
    " \n",
    "resnet50 = Model(input_tensor, output_tensor)\n",
    "resnet50.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.compile(optimizer='adamax',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "15/15 [==============================] - 4s 274ms/step - loss: 0.5686 - accuracy: 0.8583 - val_loss: 1.6594 - val_accuracy: 0.7500\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 4s 263ms/step - loss: 0.5599 - accuracy: 0.8625 - val_loss: 2.0790 - val_accuracy: 0.6500\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 4s 263ms/step - loss: 0.5583 - accuracy: 0.8542 - val_loss: 0.8535 - val_accuracy: 0.8000\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 4s 264ms/step - loss: 0.5041 - accuracy: 0.8625 - val_loss: 3.4431 - val_accuracy: 0.4125\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 4s 264ms/step - loss: 0.5610 - accuracy: 0.8667 - val_loss: 2.5451 - val_accuracy: 0.4875\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.5119 - accuracy: 0.8750 - val_loss: 1.1451 - val_accuracy: 0.7125\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 4s 264ms/step - loss: 0.5021 - accuracy: 0.8708 - val_loss: 0.3035 - val_accuracy: 0.8125\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 4s 263ms/step - loss: 0.3964 - accuracy: 0.8750 - val_loss: 1.7177 - val_accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.4561 - accuracy: 0.8750 - val_loss: 4.6382 - val_accuracy: 0.3125\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.4802 - accuracy: 0.8792 - val_loss: 0.6544 - val_accuracy: 0.7750\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.5977 - accuracy: 0.8333 - val_loss: 5.2775 - val_accuracy: 0.4750\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.4493 - accuracy: 0.8917 - val_loss: 2.2052 - val_accuracy: 0.6125\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 4s 263ms/step - loss: 0.4933 - accuracy: 0.8875 - val_loss: 4.2352 - val_accuracy: 0.3750\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.4348 - accuracy: 0.8750 - val_loss: 0.6000 - val_accuracy: 0.7000\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 4s 264ms/step - loss: 0.4456 - accuracy: 0.8792 - val_loss: 1.4172 - val_accuracy: 0.7250\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.5167 - accuracy: 0.8542 - val_loss: 0.6493 - val_accuracy: 0.7750\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.5499 - accuracy: 0.8667 - val_loss: 0.7787 - val_accuracy: 0.7250\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.4557 - accuracy: 0.8958 - val_loss: 1.4182 - val_accuracy: 0.7250\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.5105 - accuracy: 0.8542 - val_loss: 2.6500 - val_accuracy: 0.5375\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.4338 - accuracy: 0.8875 - val_loss: 2.1359 - val_accuracy: 0.5625\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 4s 271ms/step - loss: 0.6101 - accuracy: 0.8250 - val_loss: 1.1171 - val_accuracy: 0.6625\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.4088 - accuracy: 0.8958 - val_loss: 1.5165 - val_accuracy: 0.5250\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.4213 - accuracy: 0.8792 - val_loss: 1.3979 - val_accuracy: 0.6125\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.3800 - accuracy: 0.9042 - val_loss: 1.0560 - val_accuracy: 0.5750\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4613 - accuracy: 0.9000 - val_loss: 2.0081 - val_accuracy: 0.5625\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.5068 - accuracy: 0.8500 - val_loss: 1.9596 - val_accuracy: 0.6125\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4107 - accuracy: 0.8792 - val_loss: 1.7020 - val_accuracy: 0.6000\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.5858 - accuracy: 0.8542 - val_loss: 0.5832 - val_accuracy: 0.7250\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.5995 - accuracy: 0.8375 - val_loss: 2.6987 - val_accuracy: 0.5625\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.6238 - accuracy: 0.8292 - val_loss: 1.0635 - val_accuracy: 0.8125\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.3757 - accuracy: 0.8875 - val_loss: 1.8117 - val_accuracy: 0.6625\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.5208 - accuracy: 0.8292 - val_loss: 1.1728 - val_accuracy: 0.7500\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4753 - accuracy: 0.8833 - val_loss: 0.8389 - val_accuracy: 0.7625\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.4547 - accuracy: 0.8708 - val_loss: 2.5203 - val_accuracy: 0.6000\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.5714 - accuracy: 0.8500 - val_loss: 0.3511 - val_accuracy: 0.8125\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.4767 - accuracy: 0.8708 - val_loss: 0.5683 - val_accuracy: 0.8000\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.5236 - accuracy: 0.8708 - val_loss: 1.3640 - val_accuracy: 0.7375\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.5388 - accuracy: 0.8417 - val_loss: 4.0499 - val_accuracy: 0.2875\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.3905 - accuracy: 0.9042 - val_loss: 3.5690 - val_accuracy: 0.3625\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.5417 - accuracy: 0.8458 - val_loss: 5.0754 - val_accuracy: 0.3250\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.4927 - accuracy: 0.8833 - val_loss: 4.1247 - val_accuracy: 0.4375\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.6223 - accuracy: 0.8542 - val_loss: 2.3797 - val_accuracy: 0.6250\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.5480 - accuracy: 0.8625 - val_loss: 0.4987 - val_accuracy: 0.7000\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.5662 - accuracy: 0.8583 - val_loss: 1.1552 - val_accuracy: 0.5125\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.6330 - accuracy: 0.8417 - val_loss: 1.1437 - val_accuracy: 0.6625\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.5663 - accuracy: 0.8750 - val_loss: 2.3912 - val_accuracy: 0.4125\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.5050 - accuracy: 0.8500 - val_loss: 1.2033 - val_accuracy: 0.6500\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.5518 - accuracy: 0.8542 - val_loss: 0.8327 - val_accuracy: 0.8375\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.4401 - accuracy: 0.8667 - val_loss: 0.1144 - val_accuracy: 0.6714\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.5127 - accuracy: 0.8458 - val_loss: 2.7338 - val_accuracy: 0.4125\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4518 - accuracy: 0.8917 - val_loss: 1.3781 - val_accuracy: 0.7625\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.4515 - accuracy: 0.8833 - val_loss: 0.5577 - val_accuracy: 0.7375\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.5376 - accuracy: 0.8750 - val_loss: 2.0274 - val_accuracy: 0.5625\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.6449 - accuracy: 0.8292 - val_loss: 1.6200 - val_accuracy: 0.6125\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.3886 - accuracy: 0.8958 - val_loss: 0.7613 - val_accuracy: 0.7125\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.5407 - accuracy: 0.8458 - val_loss: 0.9204 - val_accuracy: 0.7750\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4253 - accuracy: 0.8917 - val_loss: 4.7067 - val_accuracy: 0.3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.6291 - accuracy: 0.8250 - val_loss: 4.9242 - val_accuracy: 0.2750\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.4646 - accuracy: 0.8583 - val_loss: 1.2215 - val_accuracy: 0.6250\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.5209 - accuracy: 0.8750 - val_loss: 2.6090 - val_accuracy: 0.4500\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.5697 - accuracy: 0.8542 - val_loss: 6.9392 - val_accuracy: 0.2750\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.4720 - accuracy: 0.8625 - val_loss: 2.1285 - val_accuracy: 0.4375\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.5534 - accuracy: 0.8375 - val_loss: 0.8767 - val_accuracy: 0.6500\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4794 - accuracy: 0.8708 - val_loss: 0.7976 - val_accuracy: 0.7000\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.5053 - accuracy: 0.8667 - val_loss: 1.2241 - val_accuracy: 0.6375\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.4324 - accuracy: 0.8875 - val_loss: 0.8594 - val_accuracy: 0.6250\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.4557 - accuracy: 0.8750 - val_loss: 0.7471 - val_accuracy: 0.8500\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.4142 - accuracy: 0.9000 - val_loss: 0.6748 - val_accuracy: 0.6875\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.5049 - accuracy: 0.8500 - val_loss: 0.6407 - val_accuracy: 0.7375\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.4091 - accuracy: 0.8958 - val_loss: 1.4986 - val_accuracy: 0.6000\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4391 - accuracy: 0.8833 - val_loss: 0.9208 - val_accuracy: 0.7875\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4621 - accuracy: 0.8625 - val_loss: 0.9735 - val_accuracy: 0.6750\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.4371 - accuracy: 0.8833 - val_loss: 2.1605 - val_accuracy: 0.5250\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4758 - accuracy: 0.8708 - val_loss: 0.9501 - val_accuracy: 0.7625\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.5379 - accuracy: 0.8458 - val_loss: 2.2266 - val_accuracy: 0.6625\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.4132 - accuracy: 0.8792 - val_loss: 0.6708 - val_accuracy: 0.7875\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.5131 - accuracy: 0.8542 - val_loss: 5.3067 - val_accuracy: 0.2625\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.4112 - accuracy: 0.8792 - val_loss: 0.6448 - val_accuracy: 0.7375\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.3690 - accuracy: 0.8958 - val_loss: 1.1533 - val_accuracy: 0.7500\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4855 - accuracy: 0.8667 - val_loss: 0.7865 - val_accuracy: 0.7875\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.4999 - accuracy: 0.8667 - val_loss: 0.6523 - val_accuracy: 0.7750\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4459 - accuracy: 0.8833 - val_loss: 0.9995 - val_accuracy: 0.6625\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4231 - accuracy: 0.9000 - val_loss: 1.7678 - val_accuracy: 0.6875\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4163 - accuracy: 0.8625 - val_loss: 0.4640 - val_accuracy: 0.7250\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.4294 - accuracy: 0.8750 - val_loss: 0.9965 - val_accuracy: 0.7750\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4463 - accuracy: 0.8875 - val_loss: 0.2733 - val_accuracy: 0.8125\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.3816 - accuracy: 0.8917 - val_loss: 1.5842 - val_accuracy: 0.6750\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.5277 - accuracy: 0.8625 - val_loss: 0.8630 - val_accuracy: 0.7000\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.4891 - accuracy: 0.8500 - val_loss: 4.4860 - val_accuracy: 0.3500\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.6385 - accuracy: 0.8292 - val_loss: 1.1992 - val_accuracy: 0.7375\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4367 - accuracy: 0.8583 - val_loss: 0.9239 - val_accuracy: 0.6250\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4080 - accuracy: 0.8667 - val_loss: 1.1368 - val_accuracy: 0.5750\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.3732 - accuracy: 0.8833 - val_loss: 1.8055 - val_accuracy: 0.7125\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.4739 - accuracy: 0.8750 - val_loss: 1.0574 - val_accuracy: 0.8250\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.5141 - accuracy: 0.8542 - val_loss: 1.3082 - val_accuracy: 0.8375\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.3286 - accuracy: 0.9125 - val_loss: 3.3565 - val_accuracy: 0.6000\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.6422 - accuracy: 0.8208 - val_loss: 2.3388 - val_accuracy: 0.5500\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.3776 - accuracy: 0.8750 - val_loss: 0.7618 - val_accuracy: 0.7000\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.4076 - accuracy: 0.8750 - val_loss: 0.8179 - val_accuracy: 0.7500\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.3534 - accuracy: 0.9292 - val_loss: 0.4308 - val_accuracy: 0.8000\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.5052 - accuracy: 0.8667 - val_loss: 1.9503 - val_accuracy: 0.6750\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.5505 - accuracy: 0.8583 - val_loss: 1.8013 - val_accuracy: 0.6000\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4825 - accuracy: 0.8792 - val_loss: 8.3906 - val_accuracy: 0.1250\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.5325 - accuracy: 0.8750 - val_loss: 2.3961 - val_accuracy: 0.4125\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.5274 - accuracy: 0.8458 - val_loss: 2.4853 - val_accuracy: 0.4500\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.5124 - accuracy: 0.8542 - val_loss: 2.0617 - val_accuracy: 0.5375\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4205 - accuracy: 0.8875 - val_loss: 1.2005 - val_accuracy: 0.7750\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.5442 - accuracy: 0.8250 - val_loss: 1.4217 - val_accuracy: 0.6125\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.6242 - accuracy: 0.8542 - val_loss: 0.8725 - val_accuracy: 0.7750\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.4746 - accuracy: 0.8833 - val_loss: 0.6713 - val_accuracy: 0.8000\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.4179 - accuracy: 0.9042 - val_loss: 0.1849 - val_accuracy: 0.8125\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.5090 - accuracy: 0.8833 - val_loss: 2.2370 - val_accuracy: 0.7125\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.3857 - accuracy: 0.8958 - val_loss: 0.5172 - val_accuracy: 0.8500\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.4624 - accuracy: 0.8750 - val_loss: 1.1212 - val_accuracy: 0.6750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4225 - accuracy: 0.8958 - val_loss: 2.5175 - val_accuracy: 0.6500\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.4595 - accuracy: 0.8750 - val_loss: 2.5921 - val_accuracy: 0.5375\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.4581 - accuracy: 0.8750 - val_loss: 1.3065 - val_accuracy: 0.6000\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.4821 - accuracy: 0.8708 - val_loss: 0.9964 - val_accuracy: 0.6375\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 4s 265ms/step - loss: 0.4497 - accuracy: 0.8542 - val_loss: 0.3490 - val_accuracy: 0.7125\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4678 - accuracy: 0.8583 - val_loss: 1.5616 - val_accuracy: 0.8000\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.5332 - accuracy: 0.8833 - val_loss: 0.9961 - val_accuracy: 0.7000\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.5814 - accuracy: 0.8458 - val_loss: 2.6214 - val_accuracy: 0.6125\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.3952 - accuracy: 0.8917 - val_loss: 1.2487 - val_accuracy: 0.7750\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4958 - accuracy: 0.8833 - val_loss: 2.3041 - val_accuracy: 0.4125\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.4164 - accuracy: 0.8917 - val_loss: 2.3260 - val_accuracy: 0.6000\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 4s 276ms/step - loss: 0.4061 - accuracy: 0.8958 - val_loss: 0.3067 - val_accuracy: 0.8750\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 4s 274ms/step - loss: 0.3765 - accuracy: 0.9125 - val_loss: 1.1203 - val_accuracy: 0.6875\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.5167 - accuracy: 0.8583 - val_loss: 0.8728 - val_accuracy: 0.5375\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.4520 - accuracy: 0.8750 - val_loss: 0.2375 - val_accuracy: 0.9000\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 4s 264ms/step - loss: 0.4245 - accuracy: 0.8958 - val_loss: 0.3040 - val_accuracy: 0.8125\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.3016 - accuracy: 0.9250 - val_loss: 0.4136 - val_accuracy: 0.9125\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.3633 - accuracy: 0.8833 - val_loss: 0.6440 - val_accuracy: 0.8875\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.2781 - accuracy: 0.9292 - val_loss: 1.1101 - val_accuracy: 0.7250\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.2959 - accuracy: 0.9292 - val_loss: 2.0546 - val_accuracy: 0.5625\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.2731 - accuracy: 0.9292 - val_loss: 1.7083 - val_accuracy: 0.7625\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.3449 - accuracy: 0.9208 - val_loss: 0.6408 - val_accuracy: 0.7500\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.3530 - accuracy: 0.9000 - val_loss: 0.6717 - val_accuracy: 0.8500\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.2733 - accuracy: 0.9333 - val_loss: 1.4685 - val_accuracy: 0.7000\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.4121 - accuracy: 0.8958 - val_loss: 0.9784 - val_accuracy: 0.7375\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.3577 - accuracy: 0.8792 - val_loss: 0.4035 - val_accuracy: 0.7625\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 4s 271ms/step - loss: 0.3378 - accuracy: 0.9125 - val_loss: 0.8846 - val_accuracy: 0.8125\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.2063 - accuracy: 0.9375 - val_loss: 1.2337 - val_accuracy: 0.5500\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.3742 - accuracy: 0.8875 - val_loss: 0.6555 - val_accuracy: 0.8625\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.2651 - accuracy: 0.9292 - val_loss: 1.8358 - val_accuracy: 0.6750\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4568 - accuracy: 0.8667 - val_loss: 1.4597 - val_accuracy: 0.6375\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.2851 - accuracy: 0.9167 - val_loss: 1.9943 - val_accuracy: 0.5875\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.3606 - accuracy: 0.8917 - val_loss: 1.2313 - val_accuracy: 0.6857\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.2754 - accuracy: 0.9083 - val_loss: 0.6269 - val_accuracy: 0.7500\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.4090 - accuracy: 0.8750 - val_loss: 0.4758 - val_accuracy: 0.8375\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.3688 - accuracy: 0.9083 - val_loss: 0.1455 - val_accuracy: 0.8375\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.4191 - accuracy: 0.8958 - val_loss: 0.1659 - val_accuracy: 0.8500\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 4s 271ms/step - loss: 0.3805 - accuracy: 0.8958 - val_loss: 2.8109 - val_accuracy: 0.5750\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.4620 - accuracy: 0.8792 - val_loss: 0.2841 - val_accuracy: 0.8375\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.4134 - accuracy: 0.8875 - val_loss: 1.6334 - val_accuracy: 0.4375\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.2758 - accuracy: 0.9208 - val_loss: 2.6519 - val_accuracy: 0.4750\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 4s 273ms/step - loss: 0.3755 - accuracy: 0.9125 - val_loss: 4.1503 - val_accuracy: 0.4375\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 4s 272ms/step - loss: 0.4188 - accuracy: 0.8958 - val_loss: 1.0080 - val_accuracy: 0.7375\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.3575 - accuracy: 0.8708 - val_loss: 1.5326 - val_accuracy: 0.7125\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.3918 - accuracy: 0.8833 - val_loss: 0.8240 - val_accuracy: 0.7375\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.3435 - accuracy: 0.8875 - val_loss: 4.8155 - val_accuracy: 0.4875\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.4740 - accuracy: 0.8792 - val_loss: 2.7357 - val_accuracy: 0.5250\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 4s 272ms/step - loss: 0.2825 - accuracy: 0.9125 - val_loss: 2.2606 - val_accuracy: 0.6125\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 4s 273ms/step - loss: 0.3536 - accuracy: 0.9042 - val_loss: 1.3255 - val_accuracy: 0.8500\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 4s 271ms/step - loss: 0.2974 - accuracy: 0.9250 - val_loss: 0.5389 - val_accuracy: 0.8250\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.3639 - accuracy: 0.9125 - val_loss: 0.8493 - val_accuracy: 0.7625\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.3582 - accuracy: 0.8792 - val_loss: 0.5342 - val_accuracy: 0.7125\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 4s 271ms/step - loss: 0.4186 - accuracy: 0.8833 - val_loss: 1.3575 - val_accuracy: 0.6375\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.3929 - accuracy: 0.8833 - val_loss: 2.2555 - val_accuracy: 0.6500\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.3559 - accuracy: 0.9125 - val_loss: 0.5433 - val_accuracy: 0.8000\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 4s 274ms/step - loss: 0.4590 - accuracy: 0.8750 - val_loss: 0.4679 - val_accuracy: 0.8375\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.2755 - accuracy: 0.9417 - val_loss: 1.7393 - val_accuracy: 0.6875\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 4s 271ms/step - loss: 0.3118 - accuracy: 0.9125 - val_loss: 1.7055 - val_accuracy: 0.5875\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.3666 - accuracy: 0.9000 - val_loss: 0.8921 - val_accuracy: 0.7500\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.2975 - accuracy: 0.9083 - val_loss: 1.6503 - val_accuracy: 0.5375\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4478 - accuracy: 0.8875 - val_loss: 0.3887 - val_accuracy: 0.8750\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.3738 - accuracy: 0.8875 - val_loss: 0.6556 - val_accuracy: 0.7750\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.4298 - accuracy: 0.8708 - val_loss: 2.1619 - val_accuracy: 0.4750\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.3930 - accuracy: 0.8958 - val_loss: 1.9888 - val_accuracy: 0.5250\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 4s 273ms/step - loss: 0.3406 - accuracy: 0.8958 - val_loss: 1.0822 - val_accuracy: 0.6625\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.3075 - accuracy: 0.9042 - val_loss: 0.5145 - val_accuracy: 0.8125\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.3356 - accuracy: 0.9208 - val_loss: 1.5400 - val_accuracy: 0.7875\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.2692 - accuracy: 0.9375 - val_loss: 1.1648 - val_accuracy: 0.7875\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 4s 274ms/step - loss: 0.3038 - accuracy: 0.9167 - val_loss: 0.4961 - val_accuracy: 0.9000\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.4390 - accuracy: 0.8833 - val_loss: 0.7008 - val_accuracy: 0.7750\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.2736 - accuracy: 0.9125 - val_loss: 0.5519 - val_accuracy: 0.5750\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.3159 - accuracy: 0.9167 - val_loss: 3.1898 - val_accuracy: 0.4875\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.4204 - accuracy: 0.8792 - val_loss: 0.5592 - val_accuracy: 0.9000\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.3375 - accuracy: 0.8917 - val_loss: 0.4454 - val_accuracy: 0.8000\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.4646 - accuracy: 0.8708 - val_loss: 1.1191 - val_accuracy: 0.6250\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.3078 - accuracy: 0.9000 - val_loss: 1.2689 - val_accuracy: 0.6250\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.3274 - accuracy: 0.9125 - val_loss: 1.8622 - val_accuracy: 0.5375\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.2308 - accuracy: 0.9292 - val_loss: 2.3362 - val_accuracy: 0.5250\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.3027 - accuracy: 0.9125 - val_loss: 3.7033 - val_accuracy: 0.4125\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.3800 - accuracy: 0.8917 - val_loss: 1.0694 - val_accuracy: 0.8125\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.3698 - accuracy: 0.8958 - val_loss: 0.3696 - val_accuracy: 0.8250\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.3056 - accuracy: 0.9125 - val_loss: 0.1811 - val_accuracy: 0.8286\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.3383 - accuracy: 0.8958 - val_loss: 1.1924 - val_accuracy: 0.7500\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.3520 - accuracy: 0.8792 - val_loss: 0.5804 - val_accuracy: 0.7125\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.2808 - accuracy: 0.9333 - val_loss: 0.4715 - val_accuracy: 0.8000\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.3632 - accuracy: 0.9042 - val_loss: 0.4000 - val_accuracy: 0.7625\n"
     ]
    }
   ],
   "source": [
    "history=resnet50.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=15,\n",
    "        epochs=200,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['training','validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model.fit() epochs 600번 수행 (최고 accuracy : 0.9417-571eopoch / 최고 val_accuracy : 0.9125-531epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.save(\"res_net50model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
