{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20201201.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHgkOKEMo8RT"
      },
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/Franck-Dernoncourt/NeuroNER/master/neuroner/data/conll2003/en/train.txt\", filename=\"train.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-iKyUrypaAv"
      },
      "source": [
        "import re\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEL4fNd8pv5t"
      },
      "source": [
        "f = open('train.txt', 'r')\n",
        "tagged_sentences = []\n",
        "sentence = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZm60mRJqjm2"
      },
      "source": [
        "for line in f:\n",
        "    if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n",
        "        if len(sentence) > 0:\n",
        "            tagged_sentences.append(sentence)\n",
        "            sentence = []\n",
        "        continue\n",
        "    splits = line.split(' ') # 공백을 기준으로 속성을 구분한다.\n",
        "    splits[-1] = re.sub(r'\\n', '', splits[-1]) # 줄바꿈 표시 \\n을 제거한다.\n",
        "    word = splits[0].lower() # 단어들은 소문자로 바꿔서 저장한다.\n",
        "    sentence.append([word, splits[-1]]) # 단어와 개체명 태깅만 기록한다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSimqnmdqwIu"
      },
      "source": [
        "# splits=\"EU NNP B-NP B-ORG\"\n",
        "# splits = splits.split(\" \")\n",
        "# re.sub(r'\\n', '', splits[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4pqCG_BskJj"
      },
      "source": [
        "len(tagged_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2R02bJFtU2e"
      },
      "source": [
        "tagged_sentences[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04TwHV-qunMZ"
      },
      "source": [
        "A = [1,2,3]\n",
        "B = ['A','B','C']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhXcrpDJvbpP"
      },
      "source": [
        "for i in zip(A,B):\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnqOHW6vvdse"
      },
      "source": [
        "re_L = list(zip(A,B))\n",
        "re_L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiscjLRsvmNf"
      },
      "source": [
        "a,b=zip(*re_L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc0dGF9Lv0x1"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D52z64u2wDhQ"
      },
      "source": [
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPeFicYMwETB"
      },
      "source": [
        "for tagged_sentence in tagged_sentences:\n",
        "    print(tagged_sentence)\n",
        "    sentence, tag_info=zip(*tagged_sentence)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha4vWHrswtKC"
      },
      "source": [
        "sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY27RHQSw_9_"
      },
      "source": [
        "tag_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZPw2MtxxB0w"
      },
      "source": [
        "sentences, ner_tags = [], [] \n",
        "for tagged_sentence in tagged_sentences: # 14,041개의 문장 샘플을 1개씩 불러온다.\n",
        "    sentence, tag_info = zip(*tagged_sentence) # 각 샘플에서 단어들은 sentence에 개체명 태깅 정보들은 tag_info에 저장.\n",
        "    sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장한다.\n",
        "    ner_tags.append(list(tag_info)) # 각 샘플에서 개체명 태깅 정보만 저장한다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44lSQH9h1wiz"
      },
      "source": [
        "sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duxdyWIq1_Wb"
      },
      "source": [
        "print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\n",
        "print('샘플의 평균 길이 : %f' % (sum(map(len, sentences))/len(sentences)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGKrCJrR2MV7"
      },
      "source": [
        "plt.hist([len(s) for s in sentences], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIZPpIPm2u6A"
      },
      "source": [
        "# 토큰화, 인코딩"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fsjf2mC3LaL"
      },
      "source": [
        "max_words = 4000 #가장 빈도가 높은 4천개 단어를 사용"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uKJ4RAH3W3D"
      },
      "source": [
        "src_tokenizer = Tokenizer(num_words=max_words, oov_token='OOV')\n",
        "src_tokenizer.fit_on_texts(sentences)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o7tldRc3tgK"
      },
      "source": [
        "src_tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kIPvlUc3ySE"
      },
      "source": [
        "tar_tokenizer = Tokenizer()\n",
        "tar_tokenizer.fit_on_texts(ner_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_dgLLkw4ReA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cHQillc4dr_"
      },
      "source": [
        "tar_tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCiuIYpH4m3S"
      },
      "source": [
        "vocab_size = max_words\n",
        "tag_size = len(tar_tokenizer.word_index) + 1\n",
        "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
        "print('개체명 태깅 정보 집합의 크기 : {}'.format(tag_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZL7mJNF49zt"
      },
      "source": [
        "#sentences\n",
        "X_train = src_tokenizer.texts_to_sequences(sentences)\n",
        "y_train = tar_tokenizer.texts_to_sequences(ner_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi1GlV2q65ue"
      },
      "source": [
        "print(X_train[0])\n",
        "print(y_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Liobm-Je5YuA"
      },
      "source": [
        "index_to_word = src_tokenizer.index_word\n",
        "index_to_ner = tar_tokenizer.index_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBgDKbre6gGh"
      },
      "source": [
        "decoded = []\n",
        "for index in X_train[0] : # 첫번째 샘플 안의 인덱스들에 대해서\n",
        "    decoded.append(index_to_word[index]) # 다시 단어로 변환\n",
        "\n",
        "print('기존 문장 : {}'.format(sentences[0]))\n",
        "print('빈도수가 낮은 단어가 OOV 처리된 문장 : {}'.format(decoded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftNu421K6qIr"
      },
      "source": [
        "max_len = 70\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
        "# X_train의 모든 샘플들의 길이를 맞출 때 뒤의 공간에 숫자 0으로 채움.\n",
        "y_train = pad_sequences(y_train, padding='post', maxlen=max_len)\n",
        "# y_train의 모든 샘플들의 길이를 맞출 때 뒤의 공간에 숫자0으로 채움."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnl_XLqd7-dx"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX-DUb4E8Etn"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxjffCap8GxR"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.2, random_state=777)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0kTBNRF8OMf"
      },
      "source": [
        "y_train = to_categorical(y_train, num_classes=tag_size)\n",
        "y_test = to_categorical(y_test, num_classes=tag_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_or03Lh_8WKy"
      },
      "source": [
        "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
        "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
        "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
        "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GehfKcy9IJH"
      },
      "source": [
        "max_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-VRZBEV9sRL"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, Bidirectional, TimeDistributed\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1NigR7_8mu1"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model.add(Dense(tag_size, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbtN1HMf9Ycp"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=128, epochs=8,  validation_data=(X_test, y_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGQ_CsTJ9uaw"
      },
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rSEoxYc95XJ"
      },
      "source": [
        "#X_test[10]\n",
        "y_predicted = model.predict(X_test[10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8-DXrCZDu1v"
      },
      "source": [
        "y_predicted=np.argmax(y_predicted, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZQwr6OcE-ms"
      },
      "source": [
        "y_predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFCOus0nDueh"
      },
      "source": [
        "true = np.argmax(y_test[10], axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIGuXi5yCxeN"
      },
      "source": [
        "#y_test[10].shape\n",
        "true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp2_MejzC9no"
      },
      "source": [
        "for w, t, pred in zip(X_test[10], true, y_predicted[0]):\n",
        "    if w != 0: # PAD값은 제외함.\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_ner[t].upper(), index_to_ner[pred].upper()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLh0d3eWEn6K"
      },
      "source": [
        "i=10 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
        "y_predicted = model.predict(np.array([X_test[i]])) # 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
        "y_predicted = np.argmax(y_predicted, axis=-1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
        "true = np.argmax(y_test[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
        "    if w != 0: # PAD값은 제외함.\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_ner[t].upper(), index_to_ner[pred].upper()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6KarephFW1R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}